"""
YouTube scraper module for social media links scraping - Modified for v2.
Uses yt-dlp for efficient video extraction with recent content focus.
"""

import logging
import os
from datetime import datetime
from typing import List
from yt_dlp import YoutubeDL


def youtube_scraper_recent(driver, account_url: str, cookie_path: str, max_videos: int = 50) -> List[str]:
    """
    Scrape recent YouTube channel video links.
    
    Args:
        driver: Chrome WebDriver instance (not used for YouTube but kept for consistency)
        account_url: YouTube channel URL to scrape
        cookie_path: Path to youtube.txt file containing cookies
        max_videos: Maximum number of recent videos to collect (default 50)
        
    Returns:
        List of video URLs
    """
    video_urls = []
    
    def extract_youtube_cookies(cookie_path: str) -> str:
        """Extract YouTube cookies and save them in Netscape format for yt-dlp."""
        youtube_cookies = []
        
        try:
            with open(cookie_path, 'r') as file:
                lines = file.readlines()
            
            for line in lines:
                line = line.strip()
                
                # Skip comments and empty lines
                if line.startswith('#') or not line:
                    continue
                
                # Split the line into fields
                fields = line.split('\t')
                if len(fields) < 7:
                    continue
                
                domain = fields[0]
                
                # Only process YouTube cookies
                if 'youtube.com' not in domain.lower():
                    continue
                
                # Parse the cookie fields
                domain_flag = fields[1].upper() == 'TRUE'
                path = fields[2]
                secure = fields[3].upper() == 'TRUE'
                expiry = fields[4]
                name = fields[5]
                value = fields[6]
                
                # Fix domain format for Netscape compliance
                # Remove leading dot if domain_flag is False
                if not domain_flag and domain.startswith('.'):
                    domain = domain[1:]
                # Add leading dot if domain_flag is True and domain doesn't start with dot
                elif domain_flag and not domain.startswith('.'):
                    domain = '.' + domain
                
                # Convert boolean values to Netscape format
                domain_flag_str = 'TRUE' if domain_flag else 'FALSE'
                secure_str = 'TRUE' if secure else 'FALSE'
                
                # Ensure expiry is a valid number
                try:
                    int(expiry)
                except ValueError:
                    expiry = '0'
                
                # Create properly formatted cookie line
                cookie_line = f"{domain}\t{domain_flag_str}\t{path}\t{secure_str}\t{expiry}\t{name}\t{value}"
                youtube_cookies.append(cookie_line)
            
            if not youtube_cookies:
                logging.warning("No YouTube cookies found in cookie file")
                return None
            
            # Save YouTube cookies to temporary file for yt-dlp
            temp_cookie_file = 'temp_youtube_cookies.txt'
            with open(temp_cookie_file, 'w') as f:
                f.write("# Netscape HTTP Cookie File\n")
                f.write("# This file is generated by yt-dlp. Do not edit.\n\n")
                for cookie in youtube_cookies:
                    f.write(cookie + '\n')
            
            logging.info(f"Extracted {len(youtube_cookies)} YouTube cookies")
            return temp_cookie_file
            
        except Exception as e:
            logging.error(f"Could not process YouTube cookies: {e}")
            return None
    
    try:
        logging.info(f"Processing YouTube channel: {account_url}")
        
        # Extract and prepare cookies for yt-dlp
        temp_cookie_file = extract_youtube_cookies(cookie_path)
        
        # Configure yt-dlp options for recent videos and shorts
        ydl_opts = {
            'quiet': True,
            'extract_flat': True,  # Only extract URLs, not full metadata
            'skip_download': True,
            'no_warnings': True,
            'playlistend': max_videos // 2,  # Split between videos and shorts
            'ignoreerrors': True,  # Continue on errors
        }
        
        # Add cookies if available
        if temp_cookie_file:
            ydl_opts['cookiefile'] = temp_cookie_file
            logging.info("Using cookies for YouTube authentication")
        
        # Clean the channel URL to get base channel
        base_channel_url = account_url.rstrip('/').split('/videos')[0].split('/shorts')[0]
        
        # Extract from both videos and shorts
        urls_to_check = [
            f"{base_channel_url}/videos",  # Regular videos
            f"{base_channel_url}/shorts"   # YouTube Shorts
        ]
        
        for url_type in urls_to_check:
            try:
                logging.info(f"Extracting from: {url_type}")
                
                with YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(url_type, download=False)
                    
                    if 'entries' in info:
                        for entry in info['entries']:
                            if entry and len(video_urls) < max_videos:
                                # With extract_flat=True, we get basic info
                                if 'id' in entry:
                                    video_url = f"https://www.youtube.com/watch?v={entry['id']}"
                                elif 'url' in entry:
                                    video_url = entry['url']
                                elif 'webpage_url' in entry:
                                    video_url = entry['webpage_url']
                                else:
                                    continue  # Skip if no URL found
                                
                                # Avoid duplicates
                                if video_url not in video_urls:
                                    title = entry.get('title', 'Unknown Title')
                                    video_urls.append(video_url)
                                    source_type = "Short" if "/shorts" in url_type else "Video"
                                    logging.info(f"Found {source_type}: {title}")
                            
                            # Stop if we've reached our limit
                            if len(video_urls) >= max_videos:
                                break
                                
            except Exception as e:
                logging.warning(f"Error extracting from {url_type}: {e}")
                continue
        
        logging.info(f"Successfully collected {len(video_urls)} video links from YouTube (Videos + Shorts)")
            
    except Exception as e:
        logging.error(f"Error processing YouTube channel {account_url}: {e}")
    
    finally:
        # Clean up temporary cookie file
        if 'temp_cookie_file' in locals() and temp_cookie_file and os.path.exists(temp_cookie_file):
            try:
                os.remove(temp_cookie_file)
            except Exception as e:
                logging.warning(f"Could not remove temporary cookie file: {e}")
    
    return video_urls
